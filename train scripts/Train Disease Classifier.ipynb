{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIHWroazK_W3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMERqbViLD3Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRmiiOefLMXo"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/AcneDataset/archive.zip' -d '/content'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_V9SsyWLQd9"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, Normalize, Resize, RandomRotation, RandomHorizontalFlip, ToTensor\n",
        "train_transform = Compose(\n",
        "        [\n",
        "            Resize((256, 256)),\n",
        "            RandomRotation(degrees= 30),\n",
        "            RandomHorizontalFlip(),\n",
        "            ToTensor(), \n",
        "            Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), \n",
        "        ]\n",
        "    )\n",
        "\n",
        "val_transform = Compose(\n",
        "        [\n",
        "            Resize((256, 256)),\n",
        "            ToTensor(), \n",
        "            Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), \n",
        "        ]\n",
        "    )\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(\"drive/MyDrive/DatasetAcne/Dataset/train\", transform=train_transform)\n",
        "val_dataset = torchvision.datasets.ImageFolder(\"drive/MyDrive/DatasetAcne/Dataset/test\", transform=val_transform)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size= 4, shuffle = True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size= 4, shuffle = False, drop_last= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBnjKCjzUjv2"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n",
        "    model = model.to(device).train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    all_losses = np.array([])\n",
        "    total_labels = np.array([])\n",
        "    total_predictions = np.array([])\n",
        "\n",
        "    for images, labels in tqdm(train_dataloader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      predicted = model(images)\n",
        "      loss = criterion(predicted, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "      total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "      total_loss += loss.item()\n",
        "      num_batches += 1\n",
        "\n",
        "    print(f\"Train loss: {total_loss / num_batches}\")\n",
        "    print(f\"Train accuracy: {(total_predictions == total_labels).mean()}\")\n",
        "\n",
        "def predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n",
        "    model = model.to(device).eval()\n",
        "    total_loss = 0\n",
        "    total_labels = []\n",
        "    num_batches = 0\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images, labels in val_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        predicted = model(images)\n",
        "        loss = criterion(predicted, labels)\n",
        "        accuracy = (predicted.argmax(1) == labels).float().mean()\n",
        "        total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "        total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "      print(f\"Val loss: {total_loss / num_batches}\")\n",
        "      print(f\"Val accuracy: {(total_predictions == total_labels).mean()}\")\n",
        "      losses = total_loss / num_batches\n",
        "      predicted_classes = total_predictions\n",
        "      true_classes = total_labels\n",
        "\n",
        "    return losses, predicted_classes, true_classes\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10):\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch number {epoch}\")\n",
        "        train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
        "        all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQOi9n2xUzrk"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.vgg13()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "n_epochs = 20\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "nOTanNVOVlO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piMVcurCMsMp"
      },
      "outputs": [],
      "source": [
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=7, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhPesX58NMXn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIRJCM2LNQqj"
      },
      "outputs": [],
      "source": [
        "set_random_seed(41)\n",
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'Model/model.pth')"
      ],
      "metadata": {
        "id": "88mhTonWPqZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}